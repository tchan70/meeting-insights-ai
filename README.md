# Meeting Insights AI ğŸ¤–

An AI-powered meeting transcript analyzer that extracts actionable insights including action items, decisions, and sentiment analysis.

![TypeScript](https://img.shields.io/badge/TypeScript-007ACC?style=flat&logo=typescript&logoColor=white)
![React](https://img.shields.io/badge/React-20232A?style=flat&logo=react&logoColor=61DAFB)
![Node.js](https://img.shields.io/badge/Node.js-43853D?style=flat&logo=node.js&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-316192?style=flat&logo=postgresql&logoColor=white)

## ğŸ“‹ Overview

This full-stack application uses OpenAI's GPT-4o-mini to analyze meeting transcripts and automatically extract:

- **Action Items** with owners, deadlines, and priorities
- **Key Decisions** (both made and pending)
- **Meeting Sentiment** and tone analysis

Built as a technical assessment for Ambr, showcasing modern full-stack development practices with TypeScript, type-safe APIs, and AI integration.

## ğŸ—ï¸ Tech Stack

### Backend
- **Runtime**: Node.js + TypeScript
- **Framework**: Express.js
- **API**: ts-rest (type-safe REST)
- **Validation**: Zod schemas
- **Database**: PostgreSQL with Prisma ORM
- **AI**: OpenAI GPT-4o-mini

### Frontend
- **Framework**: React 18 + TypeScript
- **Build Tool**: Vite
- **UI Library**: PrimeReact
- **Styling**: Tailwind CSS
- **Data Fetching**: TanStack Query
- **API Client**: ts-rest React Query

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18+
- PostgreSQL (or Docker)
- OpenAI API key ([Get one here](https://platform.openai.com/api-keys))

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/meeting-insights-ai.git
cd meeting-insights-ai
```

### 2. Set Up Backend

```bash
cd backend

# Install dependencies
npm install

# Set up environment variables
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY

# Start PostgreSQL (using Docker)
docker-compose up -d

# Initialize database
npm run db:generate
npm run db:push

# Start the server
npm run dev
```

Backend will run on `http://localhost:3001`

### 3. Set Up Frontend

```bash
cd frontend

# Install dependencies
npm install

# Start the development server
npm run dev
```

Frontend will run on `http://localhost:5173`

### 4. Test the Application

1. Open `http://localhost:5173` in your browser
2. Click "Load Sample" to populate with example transcript
3. Click "Analyze Transcript"
4. View the AI-generated insights!

## ğŸ“ Project Structure

```
meeting-insights-ai/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ index.ts              # Express server
â”‚   â”‚   â”œâ”€â”€ contract.ts           # API contract (shared with frontend)
â”‚   â”‚   â”œâ”€â”€ router.ts             # Route handlers
â”‚   â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”‚   â””â”€â”€ prisma.ts        # Prisma client
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â”œâ”€â”€ openai.service.ts    # OpenAI integration
â”‚   â”‚       â””â”€â”€ database.service.ts  # Database operations
â”‚   â”œâ”€â”€ prisma/
â”‚   â”‚   â””â”€â”€ schema.prisma        # Database schema
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ TranscriptInput.tsx
â”‚   â”‚   â”‚   â””â”€â”€ AnalysisResults.tsx
â”‚   â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”‚   â”œâ”€â”€ contract.ts      # Shared API contract
â”‚   â”‚   â”‚   â”œâ”€â”€ api-client.ts
â”‚   â”‚   â”‚   â””â”€â”€ api-query.ts
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â””â”€â”€ main.tsx
â”‚   â””â”€â”€ package.json
â”‚
â””â”€â”€ README.md
```

## ğŸ¯ Features

### Backend Features
- âœ… Type-safe REST API with ts-rest
- âœ… Comprehensive input validation with Zod
- âœ… AI-powered transcript analysis
- âœ… PostgreSQL database with Prisma
- âœ… Robust error handling
- âœ… Token limit validation
- âœ… CORS support
- âœ… Health check endpoint

### Frontend Features
- âœ… Clean, modern UI with PrimeReact
- âœ… Real-time character counter
- âœ… Sample transcript loader
- âœ… Loading and error states
- âœ… Color-coded priorities and sentiments
- âœ… Responsive design
- âœ… Type-safe API calls
- âœ… Copy and clear functionality

### AI Analysis Features
- âœ… Professional prompt engineering
- âœ… Structured JSON output
- âœ… Action item extraction with:
  - Task descriptions
  - Assigned owners
  - Deadlines
  - Priority levels (high/medium/low)
- âœ… Decision tracking:
  - Made vs pending
  - Context information
- âœ… Sentiment analysis:
  - Overall tone
  - Brief summary

## ğŸ“ API Endpoints

### POST `/api/transcripts/analyze`
Analyze a meeting transcript.

**Request:**
```json
{
  "transcript": "Meeting transcript text..."
}
```

**Response:**
```json
{
  "id": "abc123",
  "transcriptId": "xyz789",
  "sentiment": "productive",
  "sentimentSummary": "The meeting was productive...",
  "actionItems": [...],
  "decisions": [...],
  "createdAt": "2024-11-04T10:00:00Z"
}
```

### GET `/api/analyses/:id`
Retrieve a specific analysis by ID.

### GET `/api/analyses`
List all past analyses (summary view).

### GET `/health`
Health check endpoint.

## ğŸ¨ Design Decisions

### Prompt Engineering Strategy
The AI uses a carefully crafted prompt that:
- Sets context as a "professional meeting minutes specialist"
- Removes filler words and corporate jargon
- Extracts structured, actionable insights
- Uses temperature 0.3 for consistent output
- Enforces JSON mode for parseable responses

### Type Safety Approach
- Shared `contract.ts` between frontend and backend
- Zod schemas validate all inputs/outputs
- Full TypeScript coverage
- Compile-time error detection

### Error Handling
- Input validation errors (400)
- AI service failures with retry
- Database errors (500)
- Clear, user-friendly messages
- Proper logging for debugging

### UI/UX Decisions
- Card-based layout for visual hierarchy
- Color coding for priorities and statuses
- Icons for context (PrimeIcons)
- Progressive disclosure (expandable cards)
- Loading states prevent double submission

### Database Schema
```
Transcript (1) â†’ Analysis (1)
  â”œâ”€â”€ ActionItems (many)
  â””â”€â”€ Decisions (many)
```

Clean relational model with cascade deletes.

## ğŸ”§ Configuration

### Backend Environment Variables
```env
DATABASE_URL="postgresql://user:pass@localhost:5432/meeting_insights"
OPENAI_API_KEY="sk-..."
PORT=3001
NODE_ENV=development
FRONTEND_URL="http://localhost:5173"
```

### Frontend Environment Variables
```env
VITE_API_URL="http://localhost:3001"  # Optional, defaults to localhost:3001
```

## ğŸ§ª Testing

### Manual Testing

**Test with sample transcript:**
```bash
curl -X POST http://localhost:3001/api/transcripts/analyze \
  -H "Content-Type: application/json" \
  -d '{
    "transcript": "Team meeting. Sarah will complete API design by Monday. We decided on PostgreSQL."
  }'
```

**Check health:**
```bash
curl http://localhost:3001/health
```

### Test Scenarios
1. âœ… Empty transcript (should error)
2. âœ… Very long transcript (>50k chars, should error)
3. âœ… Normal transcript (should extract insights)
4. âœ… Transcript with no action items (should handle gracefully)
5. âœ… Transcript with multiple priorities (should categorize correctly)

## ğŸ“š Database Schema

```prisma
model Transcript {
  id        String    @id @default(cuid())
  content   String    @db.Text
  createdAt DateTime  @default(now())
  analysis  Analysis?
}

model Analysis {
  id               String   @id @default(cuid())
  transcriptId     String   @unique
  sentiment        String
  sentimentSummary String?  @db.Text
  actionItems      ActionItem[]
  decisions        Decision[]
}

model ActionItem {
  id          String   @id @default(cuid())
  description String   @db.Text
  owner       String?
  deadline    String?
  priority    String?
}

model Decision {
  id          String   @id @default(cuid())
  description String   @db.Text
  type        String   # "made" or "pending"
  context     String?  @db.Text
}
```

## ğŸš§ Future Improvements

With more time, I would add:

### High Priority
- [ ] Authentication and user accounts
- [ ] View past analyses (list view with search)
- [ ] Export results (PDF, Markdown, CSV)
- [ ] Transcript chunking for very long meetings (>50k chars)

### Medium Priority
- [ ] Real-time analysis progress updates
- [ ] Dark mode support
- [ ] File upload for transcripts
- [ ] Integration with task trackers (Trello, Asana)
- [ ] Email notifications for action items

### Low Priority
- [ ] Multiple LLM provider support
- [ ] Custom prompt templates
- [ ] Analytics dashboard
- [ ] Share analyses via URL
- [ ] Audio transcription integration

## ğŸ¯ Assessment Requirements Checklist

### Core Requirements
- âœ… Backend API accepting transcript via POST
- âœ… LLM integration (OpenAI GPT-4o-mini)
- âœ… Extract action items with owners/deadlines
- âœ… Extract key decisions
- âœ… Extract meeting sentiment
- âœ… Store results in PostgreSQL
- âœ… Return structured, typed responses
- âœ… React frontend with transcript input
- âœ… Display insights clearly
- âœ… Handle loading and error states

### Tech Stack
- âœ… ts-rest for API
- âœ… Zod for validation
- âœ… Prisma + PostgreSQL
- âœ… React with Vite
- âœ… TanStack Query
- âœ… TypeScript throughout
- âœ… PrimeReact for UI

### Quality Criteria
- âœ… Works reliably
- âœ… Clean, typed, well-structured code
- âœ… Thoughtful UX decisions
- âœ… Comprehensive error handling
- âœ… Clear decision documentation

## ğŸ¤” Design Decisions Explained

### Why GPT-4o-mini instead of GPT-4?
- 10x cheaper (~$0.15 vs $1.50 per 1M tokens)
- Faster response times (better UX)
- Sufficient for structured extraction tasks
- JSON mode ensures parseable output

### Why ts-rest instead of tRPC?
- More familiar REST patterns
- Easier to document and test
- Better for API-first design
- Still fully type-safe!

### Why PrimeReact?
- Rich component library out of the box
- Professional UI with minimal effort
- Good TypeScript support
- Perfect for MVPs

### How to Handle Long Transcripts?
Current approach: Reject transcripts over 50,000 characters with clear error message.

Alternative approaches considered:
1. **Chunking**: Split into segments and analyze separately
2. **Summarization**: Pre-summarize then extract insights
3. **Streaming**: Process in chunks with progress updates

Chose simple rejection for MVP; would implement chunking with more time.

## ğŸ“– Documentation

- [Backend README](./backend/README.md) - Detailed backend documentation
- [Frontend README](./frontend/README.md) - Detailed frontend documentation
- [API Contract](./backend/src/contract.ts) - Shared type definitions

## ğŸ› Troubleshooting

**Backend not starting?**
```bash
# Check PostgreSQL is running
docker-compose ps

# Regenerate Prisma client
npm run db:generate

# Check environment variables
cat .env
```

**Frontend not connecting to backend?**
- Ensure backend is running on port 3001
- Check CORS settings in backend/src/index.ts
- Verify API URL in frontend/.env

**OpenAI errors?**
- Check API key is correct
- Ensure you have credits
- Review rate limits

**Database errors?**
```bash
# Reset database
docker-compose down -v
docker-compose up -d
npm run db:push
```

## ğŸ‘¨â€ğŸ’» Development

### Running Both Servers
```bash
# Terminal 1 - Backend
cd backend && npm run dev

# Terminal 2 - Frontend
cd frontend && npm run dev

# Terminal 3 - Database GUI (optional)
cd backend && npm run db:studio
```

### Making Changes
1. Backend changes: Server auto-reloads
2. Frontend changes: HMR (Hot Module Replacement)
3. Schema changes: Run `npm run db:generate` and `npm run db:push`

## ğŸ“„ License

MIT

## ğŸ‘¤ Author

Built by [Your Name] for Ambr Technical Assessment

## ğŸ™ Acknowledgments

- Ambr team for the interesting challenge
- OpenAI for GPT-4o-mini
- PrimeReact for the UI components
- The TypeScript community

---

**Time Spent**: ~3-4 hours (as specified)

**Questions?** Email: your.email@example.com
